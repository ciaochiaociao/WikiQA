{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import quantities as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "zh2en_unit = {'公尺': 'meter', '公里': 'km'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "q = 2 * (pq.meter)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "q.units = (pq.km) **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dab5c5394a0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Quantity' object has no attribute 'array'"
     ],
     "ename": "AttributeError",
     "evalue": "'Quantity' object has no attribute 'array'",
     "output_type": "error"
    }
   ],
   "source": [
    "q.array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['T',\n '__abs__',\n '__add__',\n '__and__',\n '__array__',\n '__array_finalize__',\n '__array_function__',\n '__array_interface__',\n '__array_prepare__',\n '__array_priority__',\n '__array_struct__',\n '__array_ufunc__',\n '__array_wrap__',\n '__bool__',\n '__class__',\n '__complex__',\n '__contains__',\n '__copy__',\n '__deepcopy__',\n '__delattr__',\n '__delitem__',\n '__dict__',\n '__dir__',\n '__divmod__',\n '__doc__',\n '__eq__',\n '__float__',\n '__floordiv__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__iand__',\n '__ifloordiv__',\n '__ilshift__',\n '__imatmul__',\n '__imod__',\n '__imul__',\n '__index__',\n '__init__',\n '__init_subclass__',\n '__int__',\n '__invert__',\n '__ior__',\n '__ipow__',\n '__irshift__',\n '__isub__',\n '__iter__',\n '__itruediv__',\n '__ixor__',\n '__le__',\n '__len__',\n '__lshift__',\n '__lt__',\n '__matmul__',\n '__mod__',\n '__module__',\n '__mul__',\n '__ne__',\n '__neg__',\n '__new__',\n '__or__',\n '__pos__',\n '__pow__',\n '__radd__',\n '__rand__',\n '__rdivmod__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__rfloordiv__',\n '__rlshift__',\n '__rmatmul__',\n '__rmod__',\n '__rmul__',\n '__ror__',\n '__round__',\n '__rpow__',\n '__rrshift__',\n '__rshift__',\n '__rsub__',\n '__rtruediv__',\n '__rxor__',\n '__setattr__',\n '__setitem__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__sub__',\n '__subclasshook__',\n '__truediv__',\n '__xor__',\n '_dimensionality',\n '_reference',\n '_tolist',\n 'all',\n 'any',\n 'argmax',\n 'argmin',\n 'argpartition',\n 'argsort',\n 'astype',\n 'base',\n 'byteswap',\n 'choose',\n 'clip',\n 'compress',\n 'conj',\n 'conjugate',\n 'copy',\n 'ctypes',\n 'cumprod',\n 'cumsum',\n 'data',\n 'diagonal',\n 'dimensionality',\n 'dot',\n 'dtype',\n 'dump',\n 'dumps',\n 'fill',\n 'flags',\n 'flat',\n 'flatten',\n 'getfield',\n 'imag',\n 'item',\n 'itemset',\n 'itemsize',\n 'magnitude',\n 'max',\n 'mean',\n 'min',\n 'nanargmax',\n 'nanargmin',\n 'nanmax',\n 'nanmean',\n 'nanmin',\n 'nanstd',\n 'nansum',\n 'nbytes',\n 'ndim',\n 'newbyteorder',\n 'nonzero',\n 'partition',\n 'prod',\n 'ptp',\n 'put',\n 'ravel',\n 'real',\n 'repeat',\n 'rescale',\n 'reshape',\n 'resize',\n 'round',\n 'searchsorted',\n 'setfield',\n 'setflags',\n 'shape',\n 'simplified',\n 'size',\n 'sort',\n 'squeeze',\n 'std',\n 'strides',\n 'sum',\n 'swapaxes',\n 'take',\n 'tobytes',\n 'tofile',\n 'tolist',\n 'tostring',\n 'trace',\n 'transpose',\n 'units',\n 'var',\n 'view']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "dir(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'text': '苏东坡', 'char_b': 0, 'char_e': 3, 'ner': 'PERSON'},\n {'text': '中国', 'char_b': 4, 'char_e': 6, 'ner': 'COUNTRY'},\n {'text': '一', 'char_b': 12, 'char_e': 13, 'ner': 'NUMBER'}]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "import re\n",
    "# fix bug: google.protobuf.message.DecodeError: Error parsing message\n",
    "# ref: https://github.com/stanfordnlp/stanfordnlp/issues/154\n",
    "from google.protobuf.pyext._message import SetAllowOversizeProtos\n",
    "SetAllowOversizeProtos(True)\n",
    "\n",
    "nlp = CoreNLPClient(endpoint='http://140.109.19.190:9000', annotators=\"tokenize,ssplit,lemma,pos,ner\",\n",
    "\t\t\t\t\t\t\tstart_server=False, properties='chinese')\n",
    "\n",
    "def get_mentions_from_text(text):\n",
    "\tnlp_data = nlp.annotate(text, properties={'pipelineLanguage': 'zh', 'annotators': \"tokenize,lemma,pos,ner\"})\n",
    "\tfor mention in nlp_data.mentions:\n",
    "\t\t# def tok_ix_2_char_ix\n",
    "\t\n",
    "\t\tall_tokens = [token for sent in nlp_data.sentence for token in sent.token]\n",
    "\t\tlen_all_tokens = list(filter(bool, [len(token.originalText) for token in all_tokens]))\n",
    "\t\n",
    "\t\tassert len(len_all_tokens) == len(all_tokens)\n",
    "\t\ts = 0\n",
    "\t\ttok_char_indexes = [s]\n",
    "\t\tfor l in len_all_tokens:\n",
    "\t\t\ts += l\n",
    "\t\t\ttok_char_indexes.append(s)\n",
    "\t\n",
    "\t\t# solve the problem that tokenization does not include newlines\n",
    "\t\tfor token in all_tokens:\n",
    "\t\t\ttok_ix = token.tokenBeginIndex\n",
    "\t\t\tchar_ix = tok_char_indexes[tok_ix]\n",
    "\t\t\ttext_by_char_ix = nlp_data.text[char_ix: char_ix + len(token.originalText)]\n",
    "\t\t\tnewlines = re.findall('[\\n\\s\\t]', text_by_char_ix)\n",
    "\t\t\tif newlines:\n",
    "\t\t\t\tfor ix in range(tok_ix, len(all_tokens)):\n",
    "\t\t\t\t\ttok_char_indexes[ix] += len(newlines)\n",
    "\t\t\t# for debugging\n",
    "\t\t\t# tok_ix = token.tokenBeginIndex\n",
    "\t\t\t# char_ix = tok_char_indexes[tok_ix]\n",
    "\t\t\t# print(tok_ix, char_ix, token.originalText, passage_data.text[char_ix: char_ix + len(token.originalText)])\n",
    "\t\t\n",
    "\t\t# mention_slice = (tok_char_indexes[mention.tokenStartInSentenceInclusive], tok_char_indexes[mention.tokenEndInSentenceExclusive])\n",
    "\t\tchar_b, char_e = tok_char_indexes[mention.tokenStartInSentenceInclusive], tok_char_indexes[mention.tokenEndInSentenceExclusive]\n",
    "\t\tyield {'text': mention.entityMentionText, 'char_b': char_b, 'char_e': char_e, 'ner': mention.ner}\n",
    "\n",
    "list(get_mentions_from_text('苏东坡在中国历史上，是哪一个朝代的人？'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}